# Lecture 2

## Review of LLMs

## Running LLMs on Local Machines
1.  LM Studio (https://lmstudio.ai/)
2.  Ollama (https://ollama.com/)

## Graphical User Interface
1.  Open WebUI (https://openwebui.com/)
2.  Docker (https://www.docker.com/)

## Llama.cpp
1.  llama.cpp (https://github.com/ggerganov/llama.cpp)
2.  GGUF and GGML (https://medium.com/@phillipgimmi/what-is-gguf-and-ggml-e364834d241c)

## Recording of the lecture 2
https://moffitt.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=65a27a26-520e-4fef-a6d8-b12a015a83b8
